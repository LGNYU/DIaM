DATA:
  data_name: pascal
  split: 0
  train_list: lists/pascal/train.txt
  data_root: ./dataset/VOCdevkit/VOC2012
  val_list: lists/pascal/val.txt
  num_classes_tr: 16  # Counting background for training
  num_classes_val: 5
  use_split_coco: False
  workers: 2
  image_size: 448
  padding_label: 255
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  scale_min: 0.5
  scale_max: 2.0
  rot_min: -10
  rot_max: 10
  augmentations: ['hor_flip', 'vert_flip', 'resize']
  pin_memory: True

TRAIN:
  ckpt_path: checkpoints/
  batch_size: 8
  epochs: 100
  log_freq : 50
  save_models: True
  lr: 0.0025
  cls_lr: 0.1
  scale_lr: 2.0
  mixup: False
  lr_stepsize: 30
  momentum: 0.9
  gamma: 0.1
  nesterov: True
  weight_decay: 0.0001
  main_optim: SGD
  scheduler: cosine
  milestones: [40, 70]

MODEL:
  arch: dinov2                # resnet | dino | dinov2
  decoder: linear   # linear | upernet | mask_transformer
  decoder_cfg: {'drop_path_rate': 0.0, 'dropout': 0.1, 'n_layers': 2, 'mask_norm': True}  # mask_norm True | False
  tune_backbone: False  # whether to fine-tune the ViT backbone

  pretrained: True  # Means the backbone has been pre-trained
  bins: [1, 2, 3, 6]
  dropout: 0.1
  m_scale: False
  layers: 50
  bottleneck_dim: 512
  feature_res: [60, 60]


EVALUATION:
  episodic_val: False
  shot: 1
  random_shot: False
  norm_feat: True
  manual_seed: 42
  ckpt_used: best
  FB_param_noise: 0
  smoothing: True

  batch_size_val: 20
  n_runs: 5
  test_num: 1000
  loss_type: ce    # ce|wce|wce1|dice
  shuffle_test_data: True
  support_only_one_novel: True  # It might help the model unfairly if a single support image has information about multiple novel classes, so set to True
  use_training_images_for_supports: False
  generate_new_support_set_for_each_task: False


CLASSIFIER:
  adapt_iter: 200

EXPERIMENT:
  exp_name: dinov2_linear

DISTRIBUTED:
  gpus: [0]



