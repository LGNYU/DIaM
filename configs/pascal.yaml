DATA:
  data_name: pascal
  data_root: ./dataset/VOCdevkit/VOC2012
  train_list: lists/pascal/train.txt
  val_list: lists/pascal/val.txt
  split: 0                      # [0, 1, 2, 3] refer to PASCAL-5^i, [10, 11] refer to PASCAL-10^i
  use_split_coco: False
  workers: 0
  image_size: 417
  patch_size: 14
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  pin_memory: True
  num_classes_tr: 16
  batch_size: 32

MODEL:
  arch: dinov2                # resnet | dino | dinov2
  decoder: mask_transformer   # linear | upernet | mask_transformer
  decoder_cfg: {'drop_path_rate': 0.0, 'dropout': 0.1, 'n_layers': 2, 'mask_norm': True}  # mask_norm True | False

  pretrained: True
  bins: [1, 2, 3, 6]
  dropout: 0.1
  m_scale: False
  layers: 50
  bottleneck_dim: 512
  feature_res: [60, 60]

EVALUATION:
  ckpt_full_path: /scratch/lg3490/DIaM/results/pretrain_pascal/dinov2/split0_shot1/dino1_maskformer/best.pth
  debug: False
  ckpt_path: model_ckpt/
  load_model_id: 1
  ckpt_used: model
  shot: 1

  batch_size_val: 100
  n_runs: 5
  test_num: 1000    # -1 use all test data set
  loss_type: ce    # ce|wce|wce1|dice
  shuffle_test_data: True
  support_only_one_novel: True  # It might help the model unfairly if a single support image has information about multiple novel classes, so set to True
  use_training_images_for_supports: False
  generate_new_support_set_for_each_task: True

  manual_seed: 42
  gpus: [0]

CLASSIFIER:
  weights: [100, 1, 1, 100]
  adapt_iter: 300
  cls_lr: 0.00125
  pi_estimation_strategy: self  # ['uniform', 'self', 'imglvl', 'upperbound']
  pi_update_at: [10]
  fine_tune_base_classifier: True

EXPERIMENT:
  exp_name: dinov2_linear


# dino, image_size: 448, arch: dino 
# psp , image_size: 417, arch: resnet
